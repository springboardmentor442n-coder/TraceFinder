# -*- coding: utf-8 -*-
"""TraceFinderOfficial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eWMKrbV5kZOphsZcoitVTbCV0P5dD-qD

The notebook uses the TraceFinder Official_Dataset, which contains TIFF images captured from 11 different scanner models under two resolutions (150 dpi and 300 dpi). The implementation begins by loading and organizing all image paths, followed by preprocessing each image‚Äîgrayscale conversion, resizing, flattening, and normalization‚Äîto prepare consistent numerical feature vectors. These processed features are then fed into multiple machine-learning models to evaluate baseline performance for scanner identification. Alongside a CNN architecture, a RandomForest classifier is implemented using scikit-learn, trained on the extracted pixel-based features. The model achieves a RandomForest Accuracy of 46.59%, which is a significant improvement over the initial CNN result and demonstrates that classical ML techniques can perform reasonably well for this classification task. Overall, the notebook successfully covers the full pipeline: dataset preparation, feature extraction, model training, and performance evaluation.
"""

# Block 1: Install dependencies
!pip install --quiet opencv-python-headless numpy pandas scikit-learn scikit-image tensorflow matplotlib seaborn tqdm joblib

# Block 2: Mount Drive and set path
from google.colab import drive
drive.mount('/content/drive')

import os
DATASET_PATH = '/content/drive/MyDrive/Official_Dataset'  # <-- change if needed
assert os.path.isdir(DATASET_PATH), f"Path not found: {DATASET_PATH}"
print("Dataset root:", DATASET_PATH)

# Block 3: Inspect folder structure
import os

scanners = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])
print(f"Found {len(scanners)} scanner models.\n")

for s in scanners:
    path150 = os.path.join(DATASET_PATH, s, '150')
    path300 = os.path.join(DATASET_PATH, s, '300')
    c150 = len([f for f in os.listdir(path150) if f.lower().endswith('.tif')]) if os.path.isdir(path150) else 0
    c300 = len([f for f in os.listdir(path300) if f.lower().endswith('.tif')]) if os.path.isdir(path300) else 0
    print(f"{s}: 150 -> {c150} .tif | 300 -> {c300} .tif")

# Block 4: Load all .tif images and assign scanner + resolution labels
import cv2
import numpy as np
from tqdm import tqdm

IMG_SIZE = 256  # resize size (adjust if needed)
images, labels = [], []

for scanner in tqdm(sorted(os.listdir(DATASET_PATH)), desc="Scanners"):
    scanner_path = os.path.join(DATASET_PATH, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in ['150', '300']:
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        for fname in os.listdir(dpi_path):
            if not fname.lower().endswith('.tif'):
                continue

            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

            if img is None:
                print("‚ö†Ô∏è Skipping unreadable:", img_path)
                continue

            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)
            images.append(img)
            labels.append(f"{scanner}_{dpi}")

images = np.array(images)
labels = np.array(labels)

print("‚úÖ Loaded images:", images.shape)
print("‚úÖ Unique classes:", np.unique(labels))

# Block 5: Preprocessing helpers - normalize and compute high-pass (PRNU-like) noise
import cv2
import numpy as np
from matplotlib import pyplot as plt

def preprocess_image_gray(img):
    # img: uint8 grayscale
    img_f = img.astype(np.float32) / 255.0
    return img_f

def estimate_noise_highpass(img_f, ksize=7):
    # approximate sensor noise / PRNU by subtracting a denoised version (Gaussian blur)
    denoised = cv2.GaussianBlur(img_f, (ksize, ksize), 0)
    noise = img_f - denoised
    # normalize noise to [-1,1]
    std = noise.std() if noise.std() > 0 else 1e-6
    noise = noise / std
    return noise

# quick check on first image
if len(images) > 0:
    sample = images[0]
    sample_f = preprocess_image_gray(sample)
    sample_noise = estimate_noise_highpass(sample_f)
    plt.figure(figsize=(10,4))
    plt.subplot(1,3,1); plt.title("Original"); plt.imshow(sample, cmap='gray'); plt.axis('off')
    plt.subplot(1,3,2); plt.title("Normalized"); plt.imshow(sample_f, cmap='gray'); plt.axis('off')
    plt.subplot(1,3,3); plt.title("Highpass Noise"); plt.imshow(sample_noise, cmap='gray'); plt.axis('off')

# Block 6: Compute feature vector per image (FFT magnitude stats + LBP hist + highpass mean)
from skimage.feature import local_binary_pattern
import numpy as np

def fft_magnitude_stats(img_f):
    f = np.fft.fft2(img_f)
    fshift = np.fft.fftshift(f)
    mag = np.abs(fshift)
    # compute a few summary stats of magnitude spectrum (log scale)
    mlog = np.log1p(mag)
    return np.array([mlog.mean(), mlog.std(), np.percentile(mlog, 50), np.percentile(mlog, 90)])

def lbp_hist(img, P=8, R=1, n_bins=59):
    lbp = local_binary_pattern(img, P, R, method='uniform')
    # compute histogram over valid bins (uniform LBP gives P*(P-1)+3 bins typically; we will use n_bins)
    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
    return hist

def build_feature_vector(img_uint8):
    img_f = preprocess_image_gray(img_uint8)
    # highpass noise
    noise = estimate_noise_highpass(img_f)
    high_mean = noise.mean()
    high_std = noise.std()
    # FFT stats
    fft_stats = fft_magnitude_stats(img_f)
    # LBP hist computed on resized smaller patch to speed up
    lbp_h = lbp_hist((img_uint8 / 255.0).astype(np.float32), P=8, R=1, n_bins=36)
    # concatenate
    feat = np.concatenate([ [high_mean, high_std], fft_stats, lbp_h ])
    return feat

# Build full feature matrix
features = []
for img in images:
    features.append(build_feature_vector(img))
features = np.vstack(features)
print("Feature matrix shape:", features.shape)

# Block 7: Encode labels and split train/test
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

le = LabelEncoder()
y_enc = le.fit_transform(labels)
X_train, X_test, y_train, y_test = train_test_split(features, y_enc, test_size=0.2, stratify=y_enc, random_state=42)

print(f"Train size: {X_train.shape}, Test size: {X_test.shape}")
print("Classes:", list(le.classes_))

features[1]

# Block 8: Train RandomForest and evaluate
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print(f"üéØ RandomForest Accuracy: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=le.classes_))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title("Confusion Matrix ‚Äî RandomForest")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.show()

# Block 9: Save model and encoder
import joblib
joblib.dump(clf, '/content/TraceFinder_RF_TIFF.joblib')
joblib.dump(le, '/content/TraceFinder_LabelEncoder.joblib')
print("‚úÖ Saved: TraceFinder_RF_TIFF.joblib & TraceFinder_LabelEncoder.joblib")

# Block 10: Predict scanner source for a new .tif file
def predict_scanner(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print("Invalid image file.")
        return
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    feat = build_features(img).reshape(1, -1)
    pred = clf.predict(feat)[0]
    class_name = le.inverse_transform([pred])[0]
    probs = clf.predict_proba(feat)[0]
    confidence = np.max(probs) * 100
    print(f"üßæ Predicted Scanner: {class_name} ({confidence:.2f}% confidence)")

# Example usage:
# predict_scanner('/content/drive/MyDrive/Official_Dataset/canon220/150/sample_01.tif')







# ======================================
# 1Ô∏è‚É£  INSTALL DEPENDENCIES
# ======================================
!pip install opencv-python numpy pandas scikit-learn tensorflow matplotlib seaborn streamlit shap tqdm

# ======================================
# 2Ô∏è‚É£  IMPORT LIBRARIES
# ======================================
import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tqdm import tqdm

# ======================================
# 3Ô∏è‚É£  DATASET SETUP
# ======================================
# Mount Google Drive if your dataset is stored there
from google.colab import drive
drive.mount('/content/drive')

# Example: Change this path to where your Flatfield dataset exists
DATASET_PATH = '/content/drive/MyDrive/Flatfield'

# Check structure
for root, dirs, files in os.walk(DATASET_PATH):
    print(root, "->", len(files), "files")
    break

# ======================================
# 4Ô∏è‚É£  LOAD AND PREPROCESS IMAGES
# ======================================
IMG_SIZE = 128
images, labels = [], []

for folder in os.listdir(DATASET_PATH):
    folder_path = os.path.join(DATASET_PATH, folder)
    if not os.path.isdir(folder_path): continue
    for file in tqdm(os.listdir(folder_path), desc=f"Loading {folder}"):
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):
            img = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
            img = img / 255.0
            images.append(img)
            labels.append(folder)

X = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y = np.array(labels)

print("Total images:", len(X))
print("Classes:", np.unique(y))

# ======================================
# 5Ô∏è‚É£  ENCODE LABELS
# ======================================
le = LabelEncoder()
y_enc = le.fit_transform(y)
y_cat = to_categorical(y_enc)

X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

# ======================================
# 6Ô∏è‚É£  DATA AUGMENTATION
# ======================================
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=(0.8, 1.2),
    zoom_range=0.1
)
datagen.fit(X_train)

# ======================================
# 7Ô∏è‚É£  CNN MODEL
# ======================================
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ======================================
# 8Ô∏è‚É£  TRAIN MODEL
# ======================================
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    epochs=15,
    validation_data=(X_test, y_test),
    callbacks=[early_stop]
)

# ======================================
# 9Ô∏è‚É£  EVALUATE MODEL
# ======================================
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()

loss, acc = model.evaluate(X_test, y_test)
print(f"‚úÖ Test Accuracy: {acc*100:.2f}%")

# ======================================
# üîü  SAVE MODEL
# ======================================
model.save('/content/TraceFinder_CNN.h5')
print("Model saved as TraceFinder_CNN.h5")

# ======================================
# 11Ô∏è‚É£  SIMPLE INFERENCE FUNCTION
# ======================================
def predict_scanner(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0
    img = img.reshape(1, IMG_SIZE, IMG_SIZE, 1)
    pred = model.predict(img)
    class_name = le.inverse_transform([np.argmax(pred)])[0]
    confidence = np.max(pred) * 100
    print(f"Predicted Scanner: {class_name} ({confidence:.2f}% confidence)")

# Example usage:
# predict_scanner("/content/drive/MyDrive/Flatfield/Epson/sample1.tif")

# ======================================
# 3Ô∏è‚É£  DATASET SETUP
# ======================================
# Mount Google Drive if your dataset is stored there
from google.colab import drive
drive.mount('/content/drive')

# Example: Change this path to where your Flatfield dataset exists
DATASET_PATH = '/content/drive/MyDrive/Flatfield'

# Check structure
for root, dirs, files in os.walk(DATASET_PATH):
    print(root, "->", len(files), "files")
    break

# ======================================
# 4Ô∏è‚É£  LOAD AND PREPROCESS IMAGES (SAFE VERSION)
# ======================================
IMG_SIZE = 128
images, labels = [], []

for folder in os.listdir(DATASET_PATH):
    folder_path = os.path.join(DATASET_PATH, folder)
    if not os.path.isdir(folder_path):
        continue

    for file in tqdm(os.listdir(folder_path), desc=f"Loading {folder}"):
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff')):
            img_path = os.path.join(folder_path, file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

            # Skip unreadable or corrupted files
            if img is None:
                print(f"‚ö†Ô∏è Skipping unreadable file: {img_path}")
                continue

            try:
                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
                img = img / 255.0
                images.append(img)
                labels.append(folder)
            except Exception as e:
                print(f"‚ö†Ô∏è Error processing {file}: {e}")
                continue

X = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y = np.array(labels)

print("‚úÖ Total images loaded:", len(X))
print("‚úÖ Classes found:", np.unique(y))

# ======================================
# 5Ô∏è‚É£  ENCODE LABELS
# ======================================
le = LabelEncoder()
y_enc = le.fit_transform(y)
y_cat = to_categorical(y_enc)

X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

# ======================================
# 6Ô∏è‚É£  DATA AUGMENTATION
# ======================================
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=(0.8, 1.2),
    zoom_range=0.1
)
datagen.fit(X_train)

# ======================================
# 7Ô∏è‚É£  CNN MODEL
# ======================================
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ======================================
# 8Ô∏è‚É£  TRAIN MODEL
# ======================================
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    epochs=15,
    validation_data=(X_test, y_test),
    callbacks=[early_stop]
)

# ======================================
# 9Ô∏è‚É£  EVALUATE MODEL
# ======================================
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()

loss, acc = model.evaluate(X_test, y_test)
print(f"‚úÖ Test Accuracy: {acc*100:.2f}%")

# ======================================
# üîü  SAVE MODEL
# ======================================
model.save('/content/TraceFinder_CNN.h5')
print("Model saved as TraceFinder_CNN.h5")

# ======================================
# 11Ô∏è‚É£  SIMPLE INFERENCE FUNCTION
# ======================================
def predict_scanner(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0
    img = img.reshape(1, IMG_SIZE, IMG_SIZE, 1)
    pred = model.predict(img)
    class_name = le.inverse_transform([np.argmax(pred)])[0]
    confidence = np.max(pred) * 100
    print(f"Predicted Scanner: {class_name} ({confidence:.2f}% confidence)")

# Example usage:
# predict_scanner("/content/drive/MyDrive/Flatfield/Epson/sample1.tif")

