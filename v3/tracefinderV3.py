# -*- coding: utf-8 -*-
"""TraceFinderOfficialXGBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MVyy7Cy-W4bHOdyUU_fIdfvme5wfJhnD

The dataset contains TIFF images from multiple scanner models, with each folder representing a distinct device. The images are preprocessed by resizing, converting to grayscale, normalizing, and applying high-pass filtering to enhance scanner-specific noise patterns. Local Binary Patterns (LBP) are extracted as texture features, which are then used to train classical models like XGBoost and Random Forest, as well as a small CNN. XGBoost achieves an accuracy of 38.64%, indicating that LBP alone does not capture enough discriminative features for reliable classification. Random Forest performs slightly better but still modestly, and the CNN shows more stable behavior but is constrained by dataset size. Overall, the results suggest that scanner identification from TIFF images requires deeper feature extraction or a more robust neural model, as classical machine learning models struggle with the subtle noise signatures present in the dataset.
"""

# Block 1: Install dependencies
!pip install --quiet opencv-python-headless numpy pandas scikit-learn scikit-image matplotlib seaborn tqdm joblib xgboost

# Block 2: Mount Drive and set dataset path
from google.colab import drive
drive.mount('/content/drive')

import os
DATASET_PATH = '/content/drive/MyDrive/Official_Dataset'  # change if needed
assert os.path.isdir(DATASET_PATH), f"Path not found: {DATASET_PATH}"
print("Dataset root:", DATASET_PATH)

# Block 3: Check number of scanners and samples
scanners = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])
print(f"Found {len(scanners)} scanner folders\n")

for s in scanners:
    for res in ['150', '300']:
        path = os.path.join(DATASET_PATH, s, res)
        if os.path.isdir(path):
            count = len([f for f in os.listdir(path) if f.lower().endswith('.tif')])
            print(f"{s}/{res}: {count} .tif")

# Block 4: Load .tif images, resize, merge DPI labels
import cv2
import numpy as np
from tqdm import tqdm

IMG_SIZE = 256
images, labels = [], []

for scanner in tqdm(sorted(os.listdir(DATASET_PATH)), desc="Scanners"):
    scanner_path = os.path.join(DATASET_PATH, scanner)
    if not os.path.isdir(scanner_path): continue

    for dpi in ['150', '300']:
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path): continue

        for fname in os.listdir(dpi_path):
            if not fname.lower().endswith('.tif'): continue
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None: continue

            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)
            images.append(img)
            labels.append(scanner)   # merge 150 & 300 ‚Üí scanner only

images, labels = np.array(images), np.array(labels)
print(f"‚úÖ Loaded {len(images)} images from {len(np.unique(labels))} scanners.")
print("Scanners:", np.unique(labels))

# Block 5: Define advanced feature extraction (Fixed gradient issue)
from skimage.feature import local_binary_pattern
import scipy.signal as signal

def preprocess(img):
    return img.astype(np.float32) / 255.0

def highpass_noise(img):
    denoised = signal.wiener(img, (5,5))
    noise = img - denoised
    std = noise.std() if noise.std() > 0 else 1e-6
    return noise / std

def radial_energy(img, n_bins=6):
    f = np.fft.fftshift(np.fft.fft2(img))
    mag = np.abs(f)
    h, w = mag.shape
    cy, cx = h//2, w//2
    y, x = np.ogrid[:h, :w]
    r = np.sqrt((x-cx)**2 + (y-cy)**2)
    bins = np.linspace(0, r.max(), n_bins+1)
    energies = [mag[(r>=bins[i])&(r<bins[i+1])].mean() for i in range(n_bins)]
    return np.array(energies)

def lbp_hist(img, P=8, R=1, bins=36):
    lbp = local_binary_pattern(img, P, R, method='uniform')
    hist, _ = np.histogram(lbp.ravel(), bins=bins, range=(0,bins), density=True)
    return hist

def gradient_features(img):
    # Ensure float64 to avoid OpenCV depth conflict
    img64 = img.astype(np.float64)
    gx = cv2.Sobel(img64, cv2.CV_64F, 1, 0, ksize=3)
    gy = cv2.Sobel(img64, cv2.CV_64F, 0, 1, ksize=3)
    grad = np.sqrt(gx**2 + gy**2)
    lap_var = cv2.Laplacian(img64, cv2.CV_64F).var()
    return np.array([grad.mean(), grad.std(), lap_var])

def build_features(img):
    img_f = preprocess(img)
    noise = highpass_noise(img_f)
    feats = np.concatenate([
        [noise.mean(), noise.std()],
        radial_energy(img_f),
        lbp_hist(img_f),
        gradient_features(img_f)
    ])
    return feats

# Block 6: Generate full feature matrix
from tqdm import tqdm
features = np.array([build_features(img) for img in tqdm(images, desc="Extracting features")])
print("‚úÖ Feature matrix shape:", features.shape)

# Block 7: Encode scanner labels
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

le = LabelEncoder()
y_enc = le.fit_transform(labels)
print("Classes:", list(le.classes_))

X_train, X_test, y_train, y_test = train_test_split(features, y_enc, test_size=0.2,
                                                    stratify=y_enc, random_state=42)
print("Train size:", X_train.shape, "| Test size:", X_test.shape)

# Block 8: Train XGBoost model
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

clf = XGBClassifier(
    n_estimators=600,
    learning_rate=0.05,
    max_depth=8,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric='mlogloss',
    tree_method='hist',
    random_state=42
)

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)

print(f"üéØ XGBoost Accuracy: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Block 9: Confusion matrix heatmap
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(12,9))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title("Confusion Matrix ‚Äî XGBoost")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.show()

# Block 10: 5-fold cross-validation
from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(clf, features, y_enc, cv=cv, scoring='accuracy')
print("Cross-validation scores:", np.round(scores, 3))
print("Mean CV Accuracy:", scores.mean())

# Block 11: Save model + encoder for later inference
import joblib
joblib.dump(clf, '/content/TraceFinder_XGBoost.joblib')
joblib.dump(le, '/content/TraceFinder_LabelEncoder.joblib')
print("‚úÖ Models saved successfully!")

# Block 12: Predict scanner for a new .tif file
def predict_scanner(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print("‚ùå Could not load image:", img_path)
        return
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    feat = build_features(img).reshape(1, -1)
    pred = clf.predict(feat)[0]
    conf = np.max(clf.predict_proba(feat)) * 100
    class_name = le.inverse_transform([pred])[0]
    print(f"üßæ Predicted Scanner: {class_name} ({conf:.2f}% confidence)")

# Example:
# predict_scanner('/content/drive/MyDrive/Official_Dataset/Canon220/150/sample_01.tif')







# Block 1: Install dependencies
!pip install --quiet opencv-python-headless numpy pandas scikit-learn scikit-image tensorflow matplotlib seaborn tqdm joblib

# Block 2: Mount Drive and set path
from google.colab import drive
drive.mount('/content/drive')

import os
DATASET_PATH = '/content/drive/MyDrive/Official_Dataset'  # <-- change if needed
assert os.path.isdir(DATASET_PATH), f"Path not found: {DATASET_PATH}"
print("Dataset root:", DATASET_PATH)

# Block 3: Inspect folder structure
import os

scanners = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])
print(f"Found {len(scanners)} scanner models.\n")

for s in scanners:
    path150 = os.path.join(DATASET_PATH, s, '150')
    path300 = os.path.join(DATASET_PATH, s, '300')
    c150 = len([f for f in os.listdir(path150) if f.lower().endswith('.tif')]) if os.path.isdir(path150) else 0
    c300 = len([f for f in os.listdir(path300) if f.lower().endswith('.tif')]) if os.path.isdir(path300) else 0
    print(f"{s}: 150 -> {c150} .tif | 300 -> {c300} .tif")

# Block 4: Load all .tif images and assign scanner + resolution labels
import cv2
import numpy as np
from tqdm import tqdm

IMG_SIZE = 256  # resize size (adjust if needed)
images, labels = [], []

for scanner in tqdm(sorted(os.listdir(DATASET_PATH)), desc="Scanners"):
    scanner_path = os.path.join(DATASET_PATH, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in ['150', '300']:
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        for fname in os.listdir(dpi_path):
            if not fname.lower().endswith('.tif'):
                continue

            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

            if img is None:
                print("‚ö†Ô∏è Skipping unreadable:", img_path)
                continue

            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)
            images.append(img)
            labels.append(f"{scanner}_{dpi}")

images = np.array(images)
labels = np.array(labels)

print("‚úÖ Loaded images:", images.shape)
print("‚úÖ Unique classes:", np.unique(labels))

# Block 5: Preprocessing helpers - normalize and compute high-pass (PRNU-like) noise
import cv2
import numpy as np
from matplotlib import pyplot as plt

def preprocess_image_gray(img):
    # img: uint8 grayscale
    img_f = img.astype(np.float32) / 255.0
    return img_f

def estimate_noise_highpass(img_f, ksize=7):
    # approximate sensor noise / PRNU by subtracting a denoised version (Gaussian blur)
    denoised = cv2.GaussianBlur(img_f, (ksize, ksize), 0)
    noise = img_f - denoised
    # normalize noise to [-1,1]
    std = noise.std() if noise.std() > 0 else 1e-6
    noise = noise / std
    return noise

# quick check on first image
if len(images) > 0:
    sample = images[0]
    sample_f = preprocess_image_gray(sample)
    sample_noise = estimate_noise_highpass(sample_f)
    plt.figure(figsize=(10,4))
    plt.subplot(1,3,1); plt.title("Original"); plt.imshow(sample, cmap='gray'); plt.axis('off')
    plt.subplot(1,3,2); plt.title("Normalized"); plt.imshow(sample_f, cmap='gray'); plt.axis('off')
    plt.subplot(1,3,3); plt.title("Highpass Noise"); plt.imshow(sample_noise, cmap='gray'); plt.axis('off')

# Block 6: Compute feature vector per image (FFT magnitude stats + LBP hist + highpass mean)
from skimage.feature import local_binary_pattern
import numpy as np

def fft_magnitude_stats(img_f):
    f = np.fft.fft2(img_f)
    fshift = np.fft.fftshift(f)
    mag = np.abs(fshift)
    # compute a few summary stats of magnitude spectrum (log scale)
    mlog = np.log1p(mag)
    return np.array([mlog.mean(), mlog.std(), np.percentile(mlog, 50), np.percentile(mlog, 90)])

def lbp_hist(img, P=8, R=1, n_bins=59):
    lbp = local_binary_pattern(img, P, R, method='uniform')
    # compute histogram over valid bins (uniform LBP gives P*(P-1)+3 bins typically; we will use n_bins)
    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
    return hist

def build_feature_vector(img_uint8):
    img_f = preprocess_image_gray(img_uint8)
    # highpass noise
    noise = estimate_noise_highpass(img_f)
    high_mean = noise.mean()
    high_std = noise.std()
    # FFT stats
    fft_stats = fft_magnitude_stats(img_f)
    # LBP hist computed on resized smaller patch to speed up
    lbp_h = lbp_hist((img_uint8 / 255.0).astype(np.float32), P=8, R=1, n_bins=36)
    # concatenate
    feat = np.concatenate([ [high_mean, high_std], fft_stats, lbp_h ])
    return feat

# Build full feature matrix
features = []
for img in images:
    features.append(build_feature_vector(img))
features = np.vstack(features)
print("Feature matrix shape:", features.shape)

# Block 7: Encode labels and split train/test
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

le = LabelEncoder()
y_enc = le.fit_transform(labels)
X_train, X_test, y_train, y_test = train_test_split(features, y_enc, test_size=0.2, stratify=y_enc, random_state=42)

print(f"Train size: {X_train.shape}, Test size: {X_test.shape}")
print("Classes:", list(le.classes_))

# Block 8: Train RandomForest and evaluate
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print(f"üéØ RandomForest Accuracy: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=le.classes_))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title("Confusion Matrix ‚Äî RandomForest")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.show()

# Block 9: Save model and encoder
import joblib
joblib.dump(clf, '/content/TraceFinder_RF_TIFF.joblib')
joblib.dump(le, '/content/TraceFinder_LabelEncoder.joblib')
print("‚úÖ Saved: TraceFinder_RF_TIFF.joblib & TraceFinder_LabelEncoder.joblib")

# Block 10: Predict scanner source for a new .tif file
def predict_scanner(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print("Invalid image file.")
        return
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    feat = build_features(img).reshape(1, -1)
    pred = clf.predict(feat)[0]
    class_name = le.inverse_transform([pred])[0]
    probs = clf.predict_proba(feat)[0]
    confidence = np.max(probs) * 100
    print(f"üßæ Predicted Scanner: {class_name} ({confidence:.2f}% confidence)")

# Example usage:
# predict_scanner('/content/drive/MyDrive/Official_Dataset/canon220/150/sample_01.tif')







# ======================================
# 1Ô∏è‚É£  INSTALL DEPENDENCIES
# ======================================
!pip install opencv-python numpy pandas scikit-learn tensorflow matplotlib seaborn streamlit shap tqdm

# ======================================
# 2Ô∏è‚É£  IMPORT LIBRARIES
# ======================================
import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tqdm import tqdm

# ======================================
# 3Ô∏è‚É£  DATASET SETUP
# ======================================
# Mount Google Drive if your dataset is stored there
from google.colab import drive
drive.mount('/content/drive')

# Example: Change this path to where your Flatfield dataset exists
DATASET_PATH = '/content/drive/MyDrive/Flatfield'

# Check structure
for root, dirs, files in os.walk(DATASET_PATH):
    print(root, "->", len(files), "files")
    break

# ======================================
# 4Ô∏è‚É£  LOAD AND PREPROCESS IMAGES
# ======================================
IMG_SIZE = 128
images, labels = [], []

for folder in os.listdir(DATASET_PATH):
    folder_path = os.path.join(DATASET_PATH, folder)
    if not os.path.isdir(folder_path): continue
    for file in tqdm(os.listdir(folder_path), desc=f"Loading {folder}"):
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):
            img = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
            img = img / 255.0
            images.append(img)
            labels.append(folder)

X = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y = np.array(labels)

print("Total images:", len(X))
print("Classes:", np.unique(y))

# ======================================
# 5Ô∏è‚É£  ENCODE LABELS
# ======================================
le = LabelEncoder()
y_enc = le.fit_transform(y)
y_cat = to_categorical(y_enc)

X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

# ======================================
# 6Ô∏è‚É£  DATA AUGMENTATION
# ======================================
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=(0.8, 1.2),
    zoom_range=0.1
)
datagen.fit(X_train)

# ======================================
# 7Ô∏è‚É£  CNN MODEL
# ======================================
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ======================================
# 8Ô∏è‚É£  TRAIN MODEL
# ======================================
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    epochs=15,
    validation_data=(X_test, y_test),
    callbacks=[early_stop]
)

# ======================================
# 9Ô∏è‚É£  EVALUATE MODEL
# ======================================
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()

loss, acc = model.evaluate(X_test, y_test)
print(f"‚úÖ Test Accuracy: {acc*100:.2f}%")

# ======================================
# üîü  SAVE MODEL
# ======================================
model.save('/content/TraceFinder_CNN.h5')
print("Model saved as TraceFinder_CNN.h5")

# ======================================
# 11Ô∏è‚É£  SIMPLE INFERENCE FUNCTION
# ======================================
def predict_scanner(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0
    img = img.reshape(1, IMG_SIZE, IMG_SIZE, 1)
    pred = model.predict(img)
    class_name = le.inverse_transform([np.argmax(pred)])[0]
    confidence = np.max(pred) * 100
    print(f"Predicted Scanner: {class_name} ({confidence:.2f}% confidence)")

# Example usage:
# predict_scanner("/content/drive/MyDrive/Flatfield/Epson/sample1.tif")

# ======================================
# 3Ô∏è‚É£  DATASET SETUP
# ======================================
# Mount Google Drive if your dataset is stored there
from google.colab import drive
drive.mount('/content/drive')

# Example: Change this path to where your Flatfield dataset exists
DATASET_PATH = '/content/drive/MyDrive/Flatfield'

# Check structure
for root, dirs, files in os.walk(DATASET_PATH):
    print(root, "->", len(files), "files")
    break

# ======================================
# 4Ô∏è‚É£  LOAD AND PREPROCESS IMAGES (SAFE VERSION)
# ======================================
IMG_SIZE = 128
images, labels = [], []

for folder in os.listdir(DATASET_PATH):
    folder_path = os.path.join(DATASET_PATH, folder)
    if not os.path.isdir(folder_path):
        continue

    for file in tqdm(os.listdir(folder_path), desc=f"Loading {folder}"):
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff')):
            img_path = os.path.join(folder_path, file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

            # Skip unreadable or corrupted files
            if img is None:
                print(f"‚ö†Ô∏è Skipping unreadable file: {img_path}")
                continue

            try:
                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
                img = img / 255.0
                images.append(img)
                labels.append(folder)
            except Exception as e:
                print(f"‚ö†Ô∏è Error processing {file}: {e}")
                continue

X = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y = np.array(labels)

print("‚úÖ Total images loaded:", len(X))
print("‚úÖ Classes found:", np.unique(y))

# ======================================
# 5Ô∏è‚É£  ENCODE LABELS
# ======================================
le = LabelEncoder()
y_enc = le.fit_transform(y)
y_cat = to_categorical(y_enc)

X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

# ======================================
# 6Ô∏è‚É£  DATA AUGMENTATION
# ======================================
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=(0.8, 1.2),
    zoom_range=0.1
)
datagen.fit(X_train)

# ======================================
# 7Ô∏è‚É£  CNN MODEL
# ======================================
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ======================================
# 8Ô∏è‚É£  TRAIN MODEL
# ======================================
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    epochs=15,
    validation_data=(X_test, y_test),
    callbacks=[early_stop]
)

# ======================================
# 9Ô∏è‚É£  EVALUATE MODEL
# ======================================
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()

loss, acc = model.evaluate(X_test, y_test)
print(f"‚úÖ Test Accuracy: {acc*100:.2f}%")

# ======================================
# üîü  SAVE MODEL
# ======================================
model.save('/content/TraceFinder_CNN.h5')
print("Model saved as TraceFinder_CNN.h5")

# ======================================
# 11Ô∏è‚É£  SIMPLE INFERENCE FUNCTION
# ======================================
def predict_scanner(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0
    img = img.reshape(1, IMG_SIZE, IMG_SIZE, 1)
    pred = model.predict(img)
    class_name = le.inverse_transform([np.argmax(pred)])[0]
    confidence = np.max(pred) * 100
    print(f"Predicted Scanner: {class_name} ({confidence:.2f}% confidence)")

# Example usage:
# predict_scanner("/content/drive/MyDrive/Flatfield/Epson/sample1.tif")

